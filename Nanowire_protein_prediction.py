# -*- coding: utf-8 -*-
"""NW_prediction_Github

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DhdQB9OUz8jFdzB0e4IT51fcNlaR4vQb

##Nanowire Protein Prediction

Dependencies
"""

!pip install bio

!pip install -q condacolab
import condacolab
condacolab.install()

!pip3 install iFeatureOmegaCLI

!pip install rdkit

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import sys
from Bio import SeqIO
from google.colab import files
import numpy as np
from sklearn.feature_selection import VarianceThreshold
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn import metrics
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from os import listdir
import json
import csv
import os
from sklearn.metrics import roc_curve, auc

import iFeatureOmegaCLI

"""Data Mining"""

#Function to retrieve model performance metrics in csv file
def get_metrics(file_name, classifier_metrics, accuracy, roc, sub_group, initialize):
  tuple1 = ('sub group','Accuracy','precision','recall','f1score','roc_auc')
  with open(file_name, 'a', newline = '') as f :
    writer = csv.writer(f)
    if(initialize == True):
      writer.writerow(tuple1)
    weighted_avg = classifier_metrics.get('weighted avg')
    precision = weighted_avg['precision']
    recall = weighted_avg['recall']
    f1_score = weighted_avg['f1-score']
    tuple2 = (sub_group,accuracy,precision,recall,f1_score,roc)
    writer.writerow(tuple2)

"""Curated NCBI and Uniprot protein extraction (Positive)"""

for re in SeqIO.parse('NCBI_doconno.fasta', 'fasta'):
    print('>{}\t{}'.format(str(re.description).replace('|', '\t'), re.seq))

original_NCBI = sys.stdout
with open('NCBI.txt', 'w') as f:
    sys.stdout = f
    for re in SeqIO.parse('NCBI_doconno.fasta', 'fasta'):
      print('>{}\t{}'.format(str(re.description).replace('|', '\t'), re.seq))
    sys.stdout = original_NCBI

#files.download('NCBI.txt')

with open('NCBI.txt','r') as file1:
    NCBI_read=file1.read()

NCBI_data=[]
for each in NCBI_read.split('\n'):
    NCBI_data.append(each[1:].split('\t'))

NCBI_df=pd.DataFrame(NCBI_data)
NCBI_df = NCBI_df.drop_duplicates()
NCBI_df.columns=['Bac','sequence', 'None', 'None1']
NCBI_df = NCBI_df.drop('None', axis=1)
NCBI_df = NCBI_df.drop('None1', axis=1)
NCBI_df.head()
NCBI_df.to_csv('NCBI.csv')

for re in SeqIO.parse('Uniprot_doconno.fasta', 'fasta'):
    print('>{}\t{}'.format(str(re.description).replace('|', '\t'), re.seq))

original_uniprot = sys.stdout
with open('uniprot.txt', 'w') as f:
    sys.stdout = f
    for re in SeqIO.parse('Uniprot_doconno.fasta', 'fasta'):
      print('>{}\t{}'.format(str(re.description).replace('|', '\t'), re.seq))
    sys.stdout = original_uniprot

with open('uniprot.txt','r') as file2:
    uniprot_read=file2.read()

uniprot_data=[]

for each in uniprot_read.split('\n'):
    uniprot_data.append(each[1:].split('\t'))

uniprot_df=pd.DataFrame(uniprot_data)
uniprot_df = uniprot_df.drop_duplicates()
uniprot_df.columns=['0','1','Bac', 'sequence']
uniprot_df = uniprot_df.drop('0', axis=1)
uniprot_df = uniprot_df.drop('1', axis=1)
uniprot_df.head()
uniprot_df.to_csv("uniprot.csv")

# Input text files
file1_path = "uniprot.txt"
file2_path = "NCBI.txt"
output_file = "Positive.txt"

# Read and merge content
with open(file1_path, "r") as file1, open(file2_path, "r") as file2:
    file1_content = file1.read()
    file2_content = file2.read()

# Write to the output file
with open(output_file, "w") as merged_file:
    merged_file.write(file1_content + "\n" + file2_content)

print(f"Successfully merged {file1_path} and {file2_path} into {output_file}.")

# Merging two csv
csv_in = ["uniprot.csv", "NCBI.csv"]
csv_out = "mergedPos.csv"

skip_header = False
with open(csv_out, "w") as dest:
    for csv in csv_in:
        with open(csv, "r") as src:
            if skip_header:
                next(src)
            for line in src:
                dest.write(line)
                if line[-1] != "\n":
                    dest.write("\n")
            skip_header = True
#files.download('mergedPos.csv')

"""Negative dataset"""

import sys
from Bio import SeqIO

# Open the output file and redirect stdout
original_Negative = sys.stdout
with open('Negative.txt', 'w') as f:
    sys.stdout = f
    for i, re in enumerate(SeqIO.parse('Negative.fasta', 'fasta')):
        if i >= 999:  # Stop after 999 sequences
            break
        print('>{}\t{}'.format(str(re.description).replace('|', '\t'), re.seq))
    sys.stdout = original_Negative  # Restore original stdout

with open('Negative.txt','r') as file4:
    Negative_read=file4.read()

Negative_data=[]
for each in Negative_read.split('\n'):
    Negative_data.append(each[1:].split('\t'))

Negative_df=pd.DataFrame(Negative_data)
Negative_df = Negative_df.drop_duplicates()
Negative_df.columns=['0','1','Bac', 'sequence']
Negative_df = Negative_df.drop('0', axis=1)
Negative_df = Negative_df.drop('1', axis=1)

Negative_df.head()
Negative_df.to_csv('Negative.csv')

csv_in = ["mergedPos.csv", "Negative.csv"]
csv_out = "merged.csv"

skip_header = False
with open(csv_out, "w") as dest:
    for csv in csv_in:
        with open(csv, "r") as src:
            if skip_header:
                next(src)
            for line in src:
                dest.write(line)
                if line[-1] != "\n":
                    dest.write("\n")
            skip_header = True
#files.download('merged.csv')

from Bio import SeqIO

# Input FASTA files
fasta_files = ["NCBI_doconno.fasta", "Uniprot_doconno.fasta", "Negative.fasta"]
output_fasta = "merged.fasta"

# Read sequences from all files
sequences = []
for file in fasta_files:
    with open(file, "r") as f:
        sequences.extend(SeqIO.parse(f, "fasta"))

# Write merged sequences to output file
with open(output_fasta, "w") as f_out:
    SeqIO.write(sequences, f_out, "fasta")

"""Feature Extraction"""

protein = iFeatureOmegaCLI.iProtein('merged.fasta')
protein.display_feature_types()

#Generating Sequence Descriptor Features with iFeature
protein_descriptors = ["CTDC","TPC type 1","CTDD","CTDT","AAC","KNN",
                       "CKSAAP type 1","DPC type 1","DPC type 2","ZScale",
                       "AAIndex","PAAC","SOCNumber","Geary","TPC type 2","Moran",
                       "AC","CTriad","NMBroto","CC","GAAC","QSOrder"]
for i in range (len(protein_descriptors)):
  protein.get_descriptor(protein_descriptors[i])
  if(protein_descriptors[i] == "CKSAAP type 1"):
    protein.to_csv("CKSAAP.csv",index=True, header=True)
  elif (protein_descriptors[i] == "DPC type 1"):
    protein.to_csv("DPC1.csv",index=True, header=True)
  elif (protein_descriptors[i] == "DPC type 2"):
    protein.to_csv("DPC2.csv",index=True, header=True)
  elif (protein_descriptors[i] == "TPC type 1"):
    protein.to_csv("TPC1.csv",index=True, header=True)
  elif (protein_descriptors[i] == "TPC type 2"):
    protein.to_csv("TPC2.csv",index=True, header=True)
  elif (protein_descriptors[i] == "TPC type 2"):
    protein.to_csv("TPC2.csv",index=True, header=True)
  else:
    protein.to_csv(protein_descriptors[i]+".csv",index=True, header=True)



"""Dataset Labelling"""

with open('Positive.txt','r') as file6:
    pos_read=file6.read()

pos_data=[]

for each in pos_read.split('\n'):
    pos_data.append(each[1:].split('\t'))

pos_df=pd.DataFrame(pos_data) #changing uniprot_data to pos_data
pos_df = pos_df.drop_duplicates()
pos_df.columns=['0','1','Bac', 'sequence']
pos_df = pos_df.drop('0', axis=1)
pos_df = pos_df.drop('1', axis=1)
pos_df.head()
pos_df.to_csv('pos.csv')

with open('Negative.txt','r') as file7:
    Negative_read=file7.read()

Negative_data=[]
for each in Negative_read.split('\n'):
    Negative_data.append(each[1:].split('\t'))


Neg_df=pd.DataFrame(Negative_data)
Neg_df=pd.DataFrame(Negative_data)
Neg_df = Neg_df.drop_duplicates() #change from Negative_df to Neg_df
Neg_df.columns=['0','1','Bac','sequence']
Neg_df = Neg_df.drop('0', axis=1)
Neg_df = Neg_df.drop('1', axis=1)
Neg_df.head()
Neg_df.to_csv('Neg.csv')
#files.download('Neg.csv')

"""Subset Feature study

QSorder
"""

QSOrder_df=pd.read_csv('QSOrder.csv')
QSOrder_df = QSOrder_df.drop('Unnamed: 0',axis=1)

key_df_QSO = pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_QSO = pd.concat([key_df_QSO, QSOrder_df], axis=1)
fea_df_QSO = fea_df_QSO.set_index('sequence')
fea_df_QSO['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_QSO = pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_QSO = pos_sequence_QSO.index
for i in range (fea_df_QSO.shape[0]):
  if(fea_df_QSO.index[i] in data_pos_sequence_index_QSO):
    fea_df_QSO.at[fea_df_QSO.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_QSO = pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_QSO = neg_sequence_QSO.index
for i in range (fea_df_QSO.shape[0]):
  if(fea_df_QSO.index[i] in data_neg_sequence_index_QSO):
    fea_df_QSO.at[fea_df_QSO.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_QSO.drop(fea_df_QSO[fea_df_QSO.Class == -1].index, inplace=True)
fea_df_QSO = fea_df_QSO.dropna()
fea_df_QSO = fea_df_QSO.reset_index(drop=True)

#Separation of features and target
X_QSO = fea_df_QSO.drop('Class', axis=1)
Y_QSO = fea_df_QSO['Class']
Y_QSO = Y_QSO.values.flatten()

trainX_QSO, testX_QSO, trainY_QSO, testY_QSO = train_test_split(X_QSO, Y_QSO, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_QSO = sc.fit_transform(trainX_QSO)
testX_QSO = sc.transform(testX_QSO)

#K-Fold validation
classifier_QSO = RandomForestClassifier(n_estimators=20, random_state=42)
RF_scores = cross_val_score(classifier_QSO, trainX_QSO, trainY_QSO, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_QSO.fit(trainX_QSO, trainY_QSO)
y_pred_class_QSO = classifier_QSO.predict(testX_QSO)

cf_matrix_QSO = confusion_matrix(testY_QSO,y_pred_class_QSO)
metrics_QSO = classification_report(testY_QSO,y_pred_class_QSO)
metrics_QSO1 = classification_report(testY_QSO,y_pred_class_QSO, output_dict=True)
accuracy_QSO = accuracy_score(testY_QSO, y_pred_class_QSO)
print("accuracy:", accuracy_QSO)
print(confusion_matrix(testY_QSO,y_pred_class_QSO))
print(metrics_QSO)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_QSO, y_pred_class_QSO)
auc_keras_QSO = auc(nn_fpr_keras, nn_tpr_keras)

get_metrics('sub_group_model_metrics.csv',metrics_QSO1,accuracy_QSO,auc_keras_QSO,'QSO',True)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_QSO))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""GAAC"""

GAAC_df=pd.read_csv('GAAC.csv')
GAAC_df = GAAC_df.drop('Unnamed: 0',axis=1)

key_df_GAAC = pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_GAAC = pd.concat([key_df_GAAC, GAAC_df], axis=1)
fea_df_GAAC = fea_df_GAAC.set_index('sequence')
fea_df_GAAC['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_GAAC = pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_GAAC = pos_sequence_GAAC.index
for i in range (fea_df_GAAC.shape[0]):
  if(fea_df_GAAC.index[i] in data_pos_sequence_index_GAAC):
    fea_df_GAAC.at[fea_df_GAAC.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_GAAC = pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_GAAC = neg_sequence_GAAC.index
for i in range (fea_df_GAAC.shape[0]):
  if(fea_df_GAAC.index[i] in data_neg_sequence_index_GAAC):
    fea_df_GAAC.at[fea_df_GAAC.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_GAAC.drop(fea_df_GAAC[fea_df_GAAC.Class == -1].index, inplace=True)
fea_df_GAAC = fea_df_GAAC.dropna()
fea_df_GAAC = fea_df_GAAC.reset_index(drop=True)

#Separation of features and target
X_GAAC = fea_df_GAAC.drop('Class', axis=1)
Y_GAAC = fea_df_GAAC['Class']
Y_GAAC = Y_GAAC.values.flatten()

trainX_GAAC, testX_GAAC, trainY_GAAC, testY_GAAC = train_test_split(X_GAAC, Y_GAAC, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_GAAC = sc.fit_transform(trainX_GAAC)
testX_GAAC = sc.transform(testX_GAAC)

#K-Fold validation
classifier_GAAC = RandomForestClassifier(n_estimators=20, random_state=42)
RF_scores = cross_val_score(classifier_GAAC, trainX_GAAC, trainY_GAAC, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_GAAC.fit(trainX_GAAC, trainY_GAAC)
y_pred_class_GAAC = classifier_GAAC.predict(testX_GAAC)

cf_matrix_GAAC = confusion_matrix(testY_GAAC,y_pred_class_GAAC)
metrics_GAAC = classification_report(testY_GAAC,y_pred_class_GAAC)
metrics_GAAC1 = classification_report(testY_GAAC,y_pred_class_GAAC, output_dict=True)
accuracy_GAAC = accuracy_score(testY_GAAC, y_pred_class_GAAC)
print("accuracy:", accuracy_GAAC)
print(confusion_matrix(testY_GAAC,y_pred_class_GAAC))
print(metrics_GAAC)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_GAAC, y_pred_class_GAAC)
auc_keras_GAAC = auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_GAAC1,accuracy_GAAC,auc_keras_GAAC, 'GAAC',False)
plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_GAAC))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""CC"""

CC_df=pd.read_csv('CC.csv')
CC_df = CC_df.drop('Unnamed: 0',axis=1)

key_df_CC = pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_CC = pd.concat([key_df_CC, CC_df], axis=1)
fea_df_CC = fea_df_CC.set_index('sequence')
fea_df_CC['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_CC = pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_CC = pos_sequence_CC.index
for i in range (fea_df_CC.shape[0]):
  if(fea_df_CC.index[i] in data_pos_sequence_index_CC):
    fea_df_CC.at[fea_df_CC.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_CC = pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_CC = neg_sequence_CC.index
for i in range (fea_df_CC.shape[0]):
  if(fea_df_CC.index[i] in data_neg_sequence_index_CC):
    fea_df_CC.at[fea_df_CC.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_CC.drop(fea_df_CC[fea_df_CC.Class == -1].index, inplace=True)
fea_df_CC = fea_df_CC.dropna()
fea_df_CC = fea_df_CC.reset_index(drop=True)

#Separation of features and target
X_CC = fea_df_CC.drop('Class', axis=1)
Y_CC = fea_df_CC['Class']
Y_CC = Y_CC.values.flatten()

trainX_CC, testX_CC, trainY_CC, testY_CC = train_test_split(X_CC, Y_CC, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_CC = sc.fit_transform(trainX_CC)
testX_CC = sc.transform(testX_CC)

#K-Fold validation
classifier_CC = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_CC, trainX_CC, trainY_CC, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_CC.fit(trainX_CC, trainY_CC)
y_pred_class_CC = classifier_CC.predict(testX_CC)

cf_matrix_CC = confusion_matrix(testY_CC,y_pred_class_CC)
metrics_CC = classification_report(testY_CC,y_pred_class_CC)
metrics_CC1 = classification_report(testY_CC,y_pred_class_CC, output_dict=True)
accuracy_CC = accuracy_score(testY_CC, y_pred_class_CC)
print("accuracy:", accuracy_CC)
print(confusion_matrix(testY_CC,y_pred_class_CC))
print(metrics_CC)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_CC, y_pred_class_CC)
auc_keras_CC = auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_CC1,accuracy_CC,auc_keras_CC, 'CC', False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_CC))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""NMBroto"""

NMBroto_df=pd.read_csv('NMBroto.csv')
NMBroto_df = NMBroto_df.drop('Unnamed: 0',axis=1)

key_df_Moreau = pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_Moreau = pd.concat([key_df_Moreau, NMBroto_df], axis=1)
fea_df_Moreau = fea_df_Moreau.set_index('sequence')
fea_df_Moreau['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_Moreau = pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_Moreau = pos_sequence_Moreau.index
for i in range (fea_df_Moreau.shape[0]):
  if(fea_df_Moreau.index[i] in data_pos_sequence_index_Moreau):
    fea_df_Moreau.at[fea_df_Moreau.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_Moreau = pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_Moreau = neg_sequence_Moreau.index
for i in range (fea_df_Moreau.shape[0]):
  if(fea_df_Moreau.index[i] in data_neg_sequence_index_Moreau):
    fea_df_Moreau.at[fea_df_Moreau.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_Moreau.drop(fea_df_Moreau[fea_df_Moreau.Class == -1].index, inplace=True)
fea_df_Moreau = fea_df_Moreau.dropna()
fea_df_Moreau = fea_df_Moreau.reset_index(drop=True)

#Separation of features and target
X_Moreau = fea_df_Moreau.drop('Class', axis=1)
Y_Moreau = fea_df_Moreau['Class']
Y_Moreau = Y_Moreau.values.flatten()

trainX_Moreau, testX_Moreau, trainY_Moreau, testY_Moreau = train_test_split(X_Moreau, Y_Moreau, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_Moreau = sc.fit_transform(trainX_Moreau)
testX_Moreau = sc.transform(testX_Moreau)

#K-Fold validation
classifier_Moreau = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_Moreau, trainX_Moreau, trainY_Moreau, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_Moreau.fit(trainX_Moreau, trainY_Moreau)
y_pred_class_Moreau = classifier_Moreau.predict(testX_Moreau)

cf_matrix_Moreau = confusion_matrix(testY_Moreau,y_pred_class_Moreau)
metrics_Moreau = classification_report(testY_Moreau,y_pred_class_Moreau)
metrics_Moreau1 = classification_report(testY_Moreau,y_pred_class_Moreau, output_dict=True)
accuracy_Moreau = accuracy_score(testY_Moreau, y_pred_class_Moreau)
print("accuracy:", accuracy_Moreau)
print(confusion_matrix(testY_Moreau,y_pred_class_Moreau))
print(metrics_Moreau)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_Moreau, y_pred_class_Moreau)
auc_keras_Moreau = auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_Moreau1,accuracy_Moreau,auc_keras_Moreau,'Moreau', False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_Moreau))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""AAC"""

AAC_df=pd.read_csv('AAC.csv')
AAC_df = AAC_df.drop('Unnamed: 0',axis=1)


key_df_AAC = pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_AAC = pd.concat([key_df_AAC, AAC_df], axis=1)
fea_df_AAC = fea_df_AAC.set_index('sequence')
fea_df_AAC['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_AAC = pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_AAC = pos_sequence_AAC.index
for i in range (fea_df_AAC.shape[0]):
  if(fea_df_AAC.index[i] in data_pos_sequence_index_AAC):
    fea_df_AAC.at[fea_df_AAC.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_AAC = pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_AAC = neg_sequence_AAC.index
for i in range (fea_df_AAC.shape[0]):
  if(fea_df_AAC.index[i] in data_neg_sequence_index_AAC):
    fea_df_AAC.at[fea_df_AAC.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_AAC.drop(fea_df_AAC[fea_df_AAC.Class == -1].index, inplace=True)
fea_df_AAC = fea_df_AAC.dropna()
fea_df_AAC = fea_df_AAC.reset_index(drop=True)

#Separation of features and target
X_AAC = fea_df_AAC.drop('Class', axis=1)
Y_AAC = fea_df_AAC['Class']
Y_AAC = Y_AAC.values.flatten()

trainX_AAC, testX_AAC, trainY_AAC, testY_AAC = train_test_split(X_AAC, Y_AAC, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_AAC = sc.fit_transform(trainX_AAC)
testX_AAC = sc.transform(testX_AAC)

#K-Fold validation
classifier_AAC = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_AAC, trainX_AAC, trainY_AAC, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_AAC.fit(trainX_AAC, trainY_AAC)
y_pred_class_AAC = classifier_AAC.predict(testX_AAC)

cf_matrix_AAC = confusion_matrix(testY_AAC,y_pred_class_AAC)
metrics_AAC = classification_report(testY_AAC,y_pred_class_AAC)
metrics_AAC1 = classification_report(testY_AAC,y_pred_class_AAC, output_dict=True)
accuracy_AAC = accuracy_score(testY_AAC, y_pred_class_AAC)
print("accuracy:", accuracy_AAC)
print(confusion_matrix(testY_AAC,y_pred_class_AAC))
print(metrics_AAC)
print(accuracy_AAC)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_AAC, y_pred_class_AAC)
auc_keras_AAC = auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_AAC1,accuracy_AAC,auc_keras_AAC,'AAC', False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_AAC))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""CKSAAP"""

CKSAAP_df=pd.read_csv('CKSAAP.csv')
CKSAAP_df = CKSAAP_df.drop('Unnamed: 0',axis=1)


key_df_CKSAAP = pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_CKSAAP = pd.concat([key_df_CKSAAP, CKSAAP_df], axis=1)
fea_df_CKSAAP = fea_df_CKSAAP.set_index('sequence')
fea_df_CKSAAP['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_CKSAAP = pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_CKSAAP = pos_sequence_CKSAAP.index
for i in range (fea_df_CKSAAP.shape[0]):
  if(fea_df_CKSAAP.index[i] in data_pos_sequence_index_CKSAAP):
    fea_df_CKSAAP.at[fea_df_CKSAAP.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_CKSAAP = pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_CKSAAP = neg_sequence_CKSAAP.index
for i in range (fea_df_CKSAAP.shape[0]):
  if(fea_df_CKSAAP.index[i] in data_neg_sequence_index_CKSAAP):
    fea_df_CKSAAP.at[fea_df_CKSAAP.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_CKSAAP.drop(fea_df_CKSAAP[fea_df_CKSAAP.Class == -1].index, inplace=True)
fea_df_CKSAAP = fea_df_CKSAAP.dropna()
fea_df_CKSAAP = fea_df_CKSAAP.reset_index(drop=True)

#Separation of features and target
X_CKSAAP = fea_df_CKSAAP.drop('Class', axis=1)
Y_CKSAAP = fea_df_CKSAAP['Class']
Y_CKSAAP = Y_CKSAAP.values.flatten()

trainX_CKSAAP, testX_CKSAAP, trainY_CKSAAP, testY_CKSAAP = train_test_split(X_CKSAAP, Y_CKSAAP, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_CKSAAP = sc.fit_transform(trainX_CKSAAP)
testX_CKSAAP = sc.transform(testX_CKSAAP)

#K-Fold validation
classifier_CKSAAP = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_CKSAAP, trainX_CKSAAP, trainY_CKSAAP, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_CKSAAP.fit(trainX_CKSAAP, trainY_CKSAAP)
y_pred_class_CKSAAP = classifier_CKSAAP.predict(testX_CKSAAP)

cf_matrix_CKSAAP = confusion_matrix(testY_CKSAAP,y_pred_class_CKSAAP)
metrics_CKSAAP = classification_report(testY_CKSAAP,y_pred_class_CKSAAP)
metrics_CKSAAP1 = classification_report(testY_CKSAAP,y_pred_class_CKSAAP, output_dict=True)
accuracy_CKSAAP = accuracy_score(testY_CKSAAP, y_pred_class_CKSAAP)
print("accuracy:", accuracy_CKSAAP)
print(confusion_matrix(testY_CKSAAP,y_pred_class_CKSAAP))
print(metrics_CKSAAP)
print(accuracy_CKSAAP)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_CKSAAP, y_pred_class_CKSAAP)
auc_keras_CKSAAP = auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_CKSAAP1,accuracy_CKSAAP,auc_keras_CKSAAP,'CKSAAP',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_CKSAAP))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""CTD Composition"""

CTDC_df=pd.read_csv('CTDC.csv')
CTDC_df = CTDC_df.drop('Unnamed: 0',axis=1)


key_df_CTDC = pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_CTDC = pd.concat([key_df_CTDC, CTDC_df], axis=1)
fea_df_CTDC = fea_df_CTDC.set_index('sequence')
fea_df_CTDC['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_CTDC = pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_CTDC = pos_sequence_CTDC.index
for i in range (fea_df_CTDC.shape[0]):
  if(fea_df_CTDC.index[i] in data_pos_sequence_index_CTDC):
    fea_df_CTDC.at[fea_df_CTDC.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_CTDC = pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_CTDC = neg_sequence_CTDC.index
for i in range (fea_df_CTDC.shape[0]):
  if(fea_df_CTDC.index[i] in data_neg_sequence_index_CTDC):
    fea_df_CTDC.at[fea_df_CTDC.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_CTDC.drop(fea_df_CTDC[fea_df_CTDC.Class == -1].index, inplace=True)
fea_df_CTDC = fea_df_CTDC.dropna()
fea_df_CTDC = fea_df_CTDC.reset_index(drop=True)

#Separation of features and target
X_CTDC = fea_df_CTDC.drop('Class', axis=1)
Y_CTDC = fea_df_CTDC['Class']
Y_CTDC = Y_CTDC.values.flatten()

trainX_CTDC, testX_CTDC, trainY_CTDC, testY_CTDC = train_test_split(X_CTDC, Y_CTDC, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_CTDC = sc.fit_transform(trainX_CTDC)
testX_CTDC = sc.transform(testX_CTDC)

#K-Fold validation
classifier_CTDC = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_CTDC, trainX_CTDC, trainY_CTDC, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_CTDC.fit(trainX_CTDC, trainY_CTDC)
y_pred_class_CTDC = classifier_CTDC.predict(testX_CTDC)

cf_matrix_CTDC = confusion_matrix(testY_CTDC,y_pred_class_CTDC)
metrics_CTDC = classification_report(testY_CTDC,y_pred_class_CTDC)
metrics_CTDC1 = classification_report(testY_CTDC,y_pred_class_CTDC, output_dict=True)
accuracy_CTDC = accuracy_score(testY_CTDC, y_pred_class_CTDC)
print("accuracy:", accuracy_CTDC)
print(confusion_matrix(testY_CTDC,y_pred_class_CTDC))
print(metrics_CTDC)
print(accuracy_CTDC)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_CTDC, y_pred_class_CTDC)
auc_keras_CTDC = auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_CTDC1,accuracy_CTDC,auc_keras_CTDC,'CTDC',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_CTDC))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""CTDD"""

CTDD_df=pd.read_csv('CTDD.csv')
CTDD_df = CTDD_df.drop('Unnamed: 0',axis=1)

key_df_CTDD= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_CTDD= pd.concat([key_df_CTDD, CTDD_df], axis=1)
fea_df_CTDD= fea_df_CTDD.set_index('sequence')
fea_df_CTDD['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_CTDD= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_CTDD= pos_sequence_CTDD.index
for i in range (fea_df_CTDD.shape[0]):
  if(fea_df_CTDD.index[i] in data_pos_sequence_index_CTDD):
    fea_df_CTDD.at[fea_df_CTDD.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_CTDD= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_CTDD= neg_sequence_CTDD.index
for i in range (fea_df_CTDD.shape[0]):
  if(fea_df_CTDD.index[i] in data_neg_sequence_index_CTDD):
    fea_df_CTDD.at[fea_df_CTDD.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_CTDD.drop(fea_df_CTDD[fea_df_CTDD.Class == -1].index, inplace=True)
fea_df_CTDD= fea_df_CTDD.dropna()
fea_df_CTDD= fea_df_CTDD.reset_index(drop=True)

#Separation of features and target
X_CTDD= fea_df_CTDD.drop('Class', axis=1)
Y_CTDD= fea_df_CTDD['Class']
Y_CTDD= Y_CTDD.values.flatten()

trainX_CTDD, testX_CTDD, trainY_CTDD, testY_CTDD= train_test_split(X_CTDD, Y_CTDD, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_CTDD= sc.fit_transform(trainX_CTDD)
testX_CTDD= sc.transform(testX_CTDD)

#K-Fold validation
classifier_CTDD= RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_CTDD, trainX_CTDD, trainY_CTDD, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_CTDD.fit(trainX_CTDD, trainY_CTDD)
y_pred_class_CTDD= classifier_CTDD.predict(testX_CTDD)

cf_matrix_CTDD= confusion_matrix(testY_CTDD,y_pred_class_CTDD)
metrics_CTDD= classification_report(testY_CTDD,y_pred_class_CTDD)
metrics_CTDD1 = classification_report(testY_CTDD,y_pred_class_CTDD, output_dict=True)
accuracy_CTDD= accuracy_score(testY_CTDD, y_pred_class_CTDD)
print("accuracy:", accuracy_CTDD)
print(confusion_matrix(testY_CTDD,y_pred_class_CTDD))
print(metrics_CTDD)
print(accuracy_CTDD)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_CTDD, y_pred_class_CTDD)
auc_keras_CTDD= auc(nn_fpr_keras, nn_tpr_keras)

get_metrics('sub_group_model_metrics.csv',metrics_CTDD1,accuracy_CTDD,auc_keras_CTDD,'CTDD',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_CTDD))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""CTDT"""

CTDT_df=pd.read_csv('CTDT.csv')
CTDT_df = CTDT_df.drop('Unnamed: 0',axis=1)

key_df_CTDT= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_CTDT= pd.concat([key_df_CTDT, CTDT_df], axis=1)
fea_df_CTDT= fea_df_CTDT.set_index('sequence')
fea_df_CTDT['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_CTDT= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_CTDT= pos_sequence_CTDT.index
for i in range (fea_df_CTDT.shape[0]):
  if(fea_df_CTDT.index[i] in data_pos_sequence_index_CTDT):
    fea_df_CTDT.at[fea_df_CTDT.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_CTDT= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_CTDT= neg_sequence_CTDT.index
for i in range (fea_df_CTDT.shape[0]):
  if(fea_df_CTDT.index[i] in data_neg_sequence_index_CTDT):
    fea_df_CTDT.at[fea_df_CTDT.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_CTDT.drop(fea_df_CTDT[fea_df_CTDT.Class == -1].index, inplace=True)
fea_df_CTDT= fea_df_CTDT.dropna()
fea_df_CTDT= fea_df_CTDT.reset_index(drop=True)

#Separation of features and target
X_CTDT= fea_df_CTDT.drop('Class', axis=1)
Y_CTDT= fea_df_CTDT['Class']
Y_CTDT= Y_CTDT.values.flatten()

trainX_CTDT, testX_CTDT, trainY_CTDT, testY_CTDT= train_test_split(X_CTDT, Y_CTDT, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_CTDT= sc.fit_transform(trainX_CTDT)
testX_CTDT= sc.transform(testX_CTDT)

#K-Fold validation
classifier_CTDT= RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_CTDT, trainX_CTDT, trainY_CTDT, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_CTDT.fit(trainX_CTDT, trainY_CTDT)
y_pred_class_CTDT= classifier_CTDT.predict(testX_CTDT)

cf_matrix_CTDT= confusion_matrix(testY_CTDT,y_pred_class_CTDT)
metrics_CTDT= classification_report(testY_CTDT,y_pred_class_CTDT)
metrics_CTDT1 = classification_report(testY_CTDT,y_pred_class_CTDT, output_dict=True)
accuracy_CTDT= accuracy_score(testY_CTDT, y_pred_class_CTDT)
print("accuracy:", accuracy_CTDT)
print(confusion_matrix(testY_CTDT,y_pred_class_CTDT))
print(metrics_CTDT)
print(accuracy_CTDT)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_CTDT, y_pred_class_CTDT)
auc_keras_CTDT= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_CTDT1,accuracy_CTDT,auc_keras_CTDT,'CTDT',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_CTDT))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""DPC"""

DPC1_df=pd.read_csv('DPC1.csv')
DPC1_df = DPC1_df.drop('Unnamed: 0',axis=1)

key_df_DPC1= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_DPC1= pd.concat([key_df_DPC1, DPC1_df], axis=1)
fea_df_DPC1= fea_df_DPC1.set_index('sequence')
fea_df_DPC1['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_DPC1= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_DPC1= pos_sequence_DPC1.index
for i in range (fea_df_DPC1.shape[0]):
  if(fea_df_DPC1.index[i] in data_pos_sequence_index_DPC1):
    fea_df_DPC1.at[fea_df_DPC1.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_DPC1= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_DPC1= neg_sequence_DPC1.index
for i in range (fea_df_DPC1.shape[0]):
  if(fea_df_DPC1.index[i] in data_neg_sequence_index_DPC1):
    fea_df_DPC1.at[fea_df_DPC1.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_DPC1.drop(fea_df_DPC1[fea_df_DPC1.Class == -1].index, inplace=True)
fea_df_DPC1= fea_df_DPC1.dropna()
fea_df_DPC1= fea_df_DPC1.reset_index(drop=True)

#Separation of features and target
X_DPC1= fea_df_DPC1.drop('Class', axis=1)
Y_DPC1= fea_df_DPC1['Class']
Y_DPC1= Y_DPC1.values.flatten()

trainX_DPC1, testX_DPC1, trainY_DPC1, testY_DPC1= train_test_split(X_DPC1, Y_DPC1, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_DPC1= sc.fit_transform(trainX_DPC1)
testX_DPC1= sc.transform(testX_DPC1)

#K-Fold validation
classifier_DPC1= RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_DPC1, trainX_DPC1, trainY_DPC1, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_DPC1.fit(trainX_DPC1, trainY_DPC1)
y_pred_class_DPC1= classifier_DPC1.predict(testX_DPC1)

cf_matrix_DPC1= confusion_matrix(testY_DPC1,y_pred_class_DPC1)
metrics_DPC1= classification_report(testY_DPC1,y_pred_class_DPC1)
metrics_DPC11 = classification_report(testY_DPC1,y_pred_class_DPC1, output_dict=True)
accuracy_DPC1= accuracy_score(testY_DPC1, y_pred_class_DPC1)
print("accuracy:", accuracy_DPC1)
print(confusion_matrix(testY_DPC1,y_pred_class_DPC1))
print(metrics_DPC1)
print(accuracy_DPC1)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_DPC1, y_pred_class_DPC1)
auc_keras_DPC1= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_DPC11,accuracy_DPC1,auc_keras_DPC1,'DPC1',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_DPC1))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""DPC2"""

DPC2_df=pd.read_csv('DPC2.csv')
DPC2_df = DPC2_df.drop('Unnamed: 0',axis=1)

key_df_DPC2= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_DPC2= pd.concat([key_df_DPC2, DPC2_df], axis=1)
fea_df_DPC2= fea_df_DPC2.set_index('sequence')
fea_df_DPC2['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_DPC2= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_DPC2= pos_sequence_DPC2.index
for i in range (fea_df_DPC2.shape[0]):
  if(fea_df_DPC2.index[i] in data_pos_sequence_index_DPC2):
    fea_df_DPC2.at[fea_df_DPC2.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_DPC2= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_DPC2= neg_sequence_DPC2.index
for i in range (fea_df_DPC2.shape[0]):
  if(fea_df_DPC2.index[i] in data_neg_sequence_index_DPC2):
    fea_df_DPC2.at[fea_df_DPC2.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_DPC2.drop(fea_df_DPC2[fea_df_DPC2.Class == -1].index, inplace=True)
fea_df_DPC2= fea_df_DPC2.dropna()
fea_df_DPC2= fea_df_DPC2.reset_index(drop=True)

#Separation of features and target
X_DPC2= fea_df_DPC2.drop('Class', axis=1)
Y_DPC2= fea_df_DPC2['Class']
Y_DPC2= Y_DPC2.values.flatten()

trainX_DPC2, testX_DPC2, trainY_DPC2, testY_DPC2= train_test_split(X_DPC2, Y_DPC2, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_DPC2= sc.fit_transform(trainX_DPC2)
testX_DPC2= sc.transform(testX_DPC2)

#K-Fold validation
classifier_DPC2= RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_DPC2, trainX_DPC2, trainY_DPC2, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_DPC2.fit(trainX_DPC2, trainY_DPC2)
y_pred_class_DPC2= classifier_DPC2.predict(testX_DPC2)

cf_matrix_DPC2= confusion_matrix(testY_DPC2,y_pred_class_DPC2)
metrics_DPC2= classification_report(testY_DPC2,y_pred_class_DPC2)
metrics_DPC21 = classification_report(testY_DPC2,y_pred_class_DPC2, output_dict=True)
accuracy_DPC2= accuracy_score(testY_DPC2, y_pred_class_DPC2)
print("accuracy:", accuracy_DPC2)
print(confusion_matrix(testY_DPC2,y_pred_class_DPC2))
print(metrics_DPC2)
print(accuracy_DPC2)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_DPC2, y_pred_class_DPC2)
auc_keras_DPC2= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_DPC21,accuracy_DPC2,auc_keras_DPC2,'DPC2',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_DPC2))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""KNN"""

KNN_df=pd.read_csv('KNN.csv')
KNN_df = KNN_df.drop('Unnamed: 0',axis=1)

key_df_KNN= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_KNN= pd.concat([key_df_KNN, KNN_df], axis=1)
fea_df_KNN= fea_df_KNN.set_index('sequence')
fea_df_KNN['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_KNN= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_KNN= pos_sequence_KNN.index
for i in range (fea_df_KNN.shape[0]):
  if(fea_df_KNN.index[i] in data_pos_sequence_index_KNN):
    fea_df_KNN.at[fea_df_KNN.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_KNN= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_KNN= neg_sequence_KNN.index
for i in range (fea_df_KNN.shape[0]):
  if(fea_df_KNN.index[i] in data_neg_sequence_index_KNN):
    fea_df_KNN.at[fea_df_KNN.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_KNN.drop(fea_df_KNN[fea_df_KNN.Class == -1].index, inplace=True)
fea_df_KNN= fea_df_KNN.dropna()
fea_df_KNN= fea_df_KNN.reset_index(drop=True)

#Separation of features and target
X_KNN= fea_df_KNN.drop('Class', axis=1)
Y_KNN= fea_df_KNN['Class']
Y_KNN= Y_KNN.values.flatten()

trainX_KNN, testX_KNN, trainY_KNN, testY_KNN= train_test_split(X_KNN, Y_KNN, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_KNN = sc.fit_transform(trainX_KNN)
testX_KNN = sc.transform(testX_KNN)

#K-Fold validation
classifier_KNN = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_KNN, trainX_KNN, trainY_KNN, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_KNN.fit(trainX_KNN, trainY_KNN)
y_pred_class_KNN = classifier_KNN.predict(testX_KNN)

cf_matrix_KNN = confusion_matrix(testY_KNN,y_pred_class_KNN)
metrics_KNN = classification_report(testY_KNN,y_pred_class_KNN)
metrics_KNN1 = classification_report(testY_KNN,y_pred_class_KNN, output_dict=True)
accuracy_KNN= accuracy_score(testY_KNN, y_pred_class_KNN)
print("accuracy:", accuracy_KNN)
print(confusion_matrix(testY_KNN,y_pred_class_KNN))
print(metrics_KNN)
print(accuracy_KNN)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_KNN, y_pred_class_KNN)
auc_keras_KNN= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_KNN1,accuracy_KNN,auc_keras_KNN,'KNN',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_KNN))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""Geary"""

Geary_df=pd.read_csv('Geary.csv')
Geary_df = Geary_df.drop('Unnamed: 0',axis=1)

key_df_Geary= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_Geary= pd.concat([key_df_Geary, Geary_df], axis=1)
fea_df_Geary= fea_df_Geary.set_index('sequence')
fea_df_Geary['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_Geary= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_Geary= pos_sequence_Geary.index
for i in range (fea_df_Geary.shape[0]):
  if(fea_df_Geary.index[i] in data_pos_sequence_index_Geary):
    fea_df_Geary.at[fea_df_Geary.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_Geary= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_Geary= neg_sequence_Geary.index
for i in range (fea_df_Geary.shape[0]):
  if(fea_df_Geary.index[i] in data_neg_sequence_index_Geary):
    fea_df_Geary.at[fea_df_Geary.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_Geary.drop(fea_df_Geary[fea_df_Geary.Class == -1].index, inplace=True)
fea_df_Geary= fea_df_Geary.dropna()
fea_df_Geary= fea_df_Geary.reset_index(drop=True)

#Separation of features and target
X_Geary= fea_df_Geary.drop('Class', axis=1)
Y_Geary= fea_df_Geary['Class']
Y_Geary= Y_Geary.values.flatten()

trainX_Geary, testX_Geary, trainY_Geary, testY_Geary= train_test_split(X_Geary, Y_Geary, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_Geary = sc.fit_transform(trainX_Geary)
testX_Geary= sc.transform(testX_Geary)

#K-Fold validation
classifier_Geary = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_Geary, trainX_Geary, trainY_Geary, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_Geary.fit(trainX_Geary, trainY_Geary)
y_pred_class_Geary= classifier_Geary.predict(testX_Geary)

cf_matrix_Geary= confusion_matrix(testY_Geary,y_pred_class_Geary)
metrics_Geary = classification_report(testY_Geary,y_pred_class_Geary)
metrics_Geary1 = classification_report(testY_Geary,y_pred_class_Geary, output_dict=True)

accuracy_Geary= accuracy_score(testY_Geary, y_pred_class_Geary)
print("accuracy:", accuracy_Geary)
print(confusion_matrix(testY_Geary,y_pred_class_Geary))
print(metrics_Geary)
print(accuracy_Geary)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_Geary, y_pred_class_Geary)
auc_keras_Geary= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_Geary1,accuracy_Geary,auc_keras_Geary,'Geary',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_Geary))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""Moran"""

Moran_df=pd.read_csv('Moran.csv')
Moran_df = Moran_df.drop('Unnamed: 0',axis=1)

key_df_Moran= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_Moran= pd.concat([key_df_Moran, Moran_df], axis=1)
fea_df_Moran= fea_df_Moran.set_index('sequence')
fea_df_Moran['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_Moran= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_Moran= pos_sequence_Moran.index
for i in range (fea_df_Moran.shape[0]):
  if(fea_df_Moran.index[i] in data_pos_sequence_index_Moran):
    fea_df_Moran.at[fea_df_Moran.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_Moran= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_Moran= neg_sequence_Moran.index
for i in range (fea_df_Moran.shape[0]):
  if(fea_df_Moran.index[i] in data_neg_sequence_index_Moran):
    fea_df_Moran.at[fea_df_Moran.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_Moran.drop(fea_df_Moran[fea_df_Moran.Class == -1].index, inplace=True)
fea_df_Moran= fea_df_Moran.dropna()
fea_df_Moran= fea_df_Moran.reset_index(drop=True)

#Separation of features and target
X_Moran= fea_df_Moran.drop('Class', axis=1)
Y_Moran= fea_df_Moran['Class']
Y_Moran= Y_Moran.values.flatten()

trainX_Moran, testX_Moran, trainY_Moran, testY_Moran= train_test_split(X_Moran, Y_Moran, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_Moran = sc.fit_transform(trainX_Moran)
testX_Moran= sc.transform(testX_Moran)

#K-Fold validation
classifier_Moran = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_Moran, trainX_Moran, trainY_Moran, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_Moran.fit(trainX_Moran, trainY_Moran)
y_pred_class_Moran= classifier_Moran.predict(testX_Moran)

cf_matrix_Moran= confusion_matrix(testY_Moran,y_pred_class_Moran)
metrics_Moran = classification_report(testY_Moran,y_pred_class_Moran)
metrics_Moran1 = classification_report(testY_Moran,y_pred_class_Moran, output_dict=True)

accuracy_Moran= accuracy_score(testY_Moran, y_pred_class_Moran)
print("accuracy:", accuracy_Moran)
print(confusion_matrix(testY_Moran,y_pred_class_Moran))
print(metrics_Moran)
print(accuracy_Moran)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_Moran, y_pred_class_Moran)
auc_keras_Moran= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_Moran1,accuracy_Moran,auc_keras_Moran,'Moran',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_Moran))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""SOCNumber"""

SOC_df=pd.read_csv('SOCNumber.csv')
SOC_df = SOC_df.drop('Unnamed: 0',axis=1)

key_df_SOC= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_SOC= pd.concat([key_df_SOC, SOC_df], axis=1)
fea_df_SOC= fea_df_SOC.set_index('sequence')
fea_df_SOC['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_SOC= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_SOC= pos_sequence_SOC.index
for i in range (fea_df_SOC.shape[0]):
  if(fea_df_SOC.index[i] in data_pos_sequence_index_SOC):
    fea_df_SOC.at[fea_df_SOC.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_SOC= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_SOC= neg_sequence_SOC.index
for i in range (fea_df_SOC.shape[0]):
  if(fea_df_SOC.index[i] in data_neg_sequence_index_SOC):
    fea_df_SOC.at[fea_df_SOC.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_SOC.drop(fea_df_SOC[fea_df_SOC.Class == -1].index, inplace=True)
fea_df_SOC= fea_df_SOC.dropna()
fea_df_SOC= fea_df_SOC.reset_index(drop=True)

#Separation of features and target
X_SOC= fea_df_SOC.drop('Class', axis=1)
Y_SOC= fea_df_SOC['Class']
Y_SOC= Y_SOC.values.flatten()

trainX_SOC, testX_SOC, trainY_SOC, testY_SOC= train_test_split(X_SOC, Y_SOC, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_SOC = sc.fit_transform(trainX_SOC)
testX_SOC= sc.transform(testX_SOC)

#K-Fold validation
classifier_SOC = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_SOC, trainX_SOC, trainY_SOC, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_SOC.fit(trainX_SOC, trainY_SOC)
y_pred_class_SOC= classifier_SOC.predict(testX_SOC)

cf_matrix_SOC = confusion_matrix(testY_SOC,y_pred_class_SOC)
metrics_SOC = classification_report(testY_SOC,y_pred_class_SOC)
metrics_SOC1 = classification_report(testY_SOC,y_pred_class_SOC, output_dict=True)
accuracy_SOC= accuracy_score(testY_SOC, y_pred_class_SOC)
print("accuracy:", accuracy_SOC)
print(confusion_matrix(testY_SOC,y_pred_class_SOC))
print(metrics_SOC)
print(accuracy_SOC)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_SOC, y_pred_class_SOC)
auc_keras_SOC= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_SOC1,accuracy_SOC,auc_keras_SOC,'SOCNumber', False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_SOC))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""AC"""

AC_df=pd.read_csv('AC.csv')
AC_df = AC_df.drop('Unnamed: 0',axis=1)

key_df_AC= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_AC= pd.concat([key_df_AC, AC_df], axis=1)
fea_df_AC= fea_df_AC.set_index('sequence')
fea_df_AC['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_AC= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_AC= pos_sequence_AC.index
for i in range (fea_df_AC.shape[0]):
  if(fea_df_AC.index[i] in data_pos_sequence_index_AC):
    fea_df_AC.at[fea_df_AC.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_AC= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_AC= neg_sequence_AC.index
for i in range (fea_df_AC.shape[0]):
  if(fea_df_AC.index[i] in data_neg_sequence_index_AC):
    fea_df_AC.at[fea_df_AC.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_AC.drop(fea_df_AC[fea_df_AC.Class == -1].index, inplace=True)
fea_df_AC= fea_df_AC.dropna()
fea_df_AC= fea_df_AC.reset_index(drop=True)

#Separation of features and target
X_AC= fea_df_AC.drop('Class', axis=1)
Y_AC= fea_df_AC['Class']
Y_AC= Y_AC.values.flatten()

trainX_AC, testX_AC, trainY_AC, testY_AC= train_test_split(X_AC, Y_AC, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_AC = sc.fit_transform(trainX_AC)
testX_AC = sc.transform(testX_AC)

#K-Fold validation
classifier_AC = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_AC, trainX_AC, trainY_AC, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_AC.fit(trainX_AC, trainY_AC)
y_pred_class_AC= classifier_AC.predict(testX_AC)

cf_matrix_AC= confusion_matrix(testY_AC,y_pred_class_AC)
metrics_AC = classification_report(testY_AC,y_pred_class_AC)
metrics_AC1 = classification_report(testY_AC,y_pred_class_AC, output_dict=True)
accuracy_AC= accuracy_score(testY_AC, y_pred_class_AC)
print("accuracy:", accuracy_AC)
print(confusion_matrix(testY_AC,y_pred_class_AC))
print(metrics_AC)
print(accuracy_AC)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_AC, y_pred_class_AC)
auc_keras_AC= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_AC1,accuracy_AC,auc_keras_AC,'AC',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_AC))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""AAindex"""

AA_df=pd.read_csv('AAIndex.csv')
AA_df = AA_df.drop('Unnamed: 0',axis=1)

key_df_AA= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_AA= pd.concat([key_df_AA, AA_df], axis=1)
fea_df_AA= fea_df_AA.set_index('sequence')
fea_df_AA['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_AA= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_AA= pos_sequence_AA.index
for i in range (fea_df_AA.shape[0]):
  if(fea_df_AA.index[i] in data_pos_sequence_index_AA):
    fea_df_AA.at[fea_df_AA.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_AA= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_AA= neg_sequence_AA.index
for i in range (fea_df_AA.shape[0]):
  if(fea_df_AA.index[i] in data_neg_sequence_index_AA):
    fea_df_AA.at[fea_df_AA.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_AA.drop(fea_df_AA[fea_df_AA.Class == -1].index, inplace=True)
fea_df_AA= fea_df_AA.dropna()
fea_df_AA= fea_df_AA.reset_index(drop=True)

#Separation of features and target
X_AA= fea_df_AA.drop('Class', axis=1)
Y_AA= fea_df_AA['Class']
Y_AA= Y_AA.values.flatten()

trainX_AA, testX_AA, trainY_AA, testY_AA= train_test_split(X_AA, Y_AA, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_AA = sc.fit_transform(trainX_AA)
testX_AA = sc.transform(testX_AA)

#K-Fold validation
classifier_AA = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_AA, trainX_AA, trainY_AA, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_AA.fit(trainX_AA, trainY_AA)
y_pred_class_AA= classifier_AA.predict(testX_AA)

cf_matrix_AA = confusion_matrix(testY_AA,y_pred_class_AA)
metrics_AA = classification_report(testY_AA,y_pred_class_AA)
metrics_AA1 = classification_report(testY_AA,y_pred_class_AA, output_dict=True)
accuracy_AA= accuracy_score(testY_AA, y_pred_class_AA)
print("accuracy:", accuracy_AA)
print(confusion_matrix(testY_AA,y_pred_class_AA))
print(metrics_AA)
print(accuracy_AA)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_AA, y_pred_class_AA)
auc_keras_AA= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_AA1,accuracy_AA,auc_keras_AA,'AAIndex',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_AA))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""PAAC"""

PAAC_df=pd.read_csv('PAAC.csv')
PAAC_df = PAAC_df.drop('Unnamed: 0',axis=1)

key_df_PAAC= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_PAAC= pd.concat([key_df_PAAC, PAAC_df], axis=1)
fea_df_PAAC= fea_df_PAAC.set_index('sequence')
fea_df_PAAC['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_PAAC= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_PAAC= pos_sequence_PAAC.index
for i in range (fea_df_PAAC.shape[0]):
  if(fea_df_PAAC.index[i] in data_pos_sequence_index_PAAC):
    fea_df_PAAC.at[fea_df_PAAC.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_PAAC= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_PAAC= neg_sequence_PAAC.index
for i in range (fea_df_PAAC.shape[0]):
  if(fea_df_PAAC.index[i] in data_neg_sequence_index_PAAC):
    fea_df_PAAC.at[fea_df_PAAC.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_PAAC.drop(fea_df_PAAC[fea_df_PAAC.Class == -1].index, inplace=True)
fea_df_PAAC= fea_df_PAAC.dropna()
fea_df_PAAC= fea_df_PAAC.reset_index(drop=True)

#Separation of features and target
X_PAAC= fea_df_PAAC.drop('Class', axis=1)
Y_PAAC= fea_df_PAAC['Class']
Y_PAAC= Y_PAAC.values.flatten()

trainX_PAAC, testX_PAAC, trainY_PAAC, testY_PAAC= train_test_split(X_PAAC, Y_PAAC, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_PAAC = sc.fit_transform(trainX_PAAC)
testX_PAAC= sc.transform(testX_PAAC)

#K-Fold validation
classifier_PAAC = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_PAAC, trainX_PAAC, trainY_PAAC, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_PAAC.fit(trainX_PAAC, trainY_PAAC)
y_pred_class_PAAC = classifier_PAAC.predict(testX_PAAC)

cf_matrix_PAAC = confusion_matrix(testY_PAAC,y_pred_class_PAAC)
metrics_PAAC = classification_report(testY_PAAC,y_pred_class_PAAC)
metrics_PAAC1 = classification_report(testY_PAAC,y_pred_class_PAAC, output_dict=True)
accuracy_PAAC= accuracy_score(testY_PAAC, y_pred_class_PAAC)
print("accuracy:", accuracy_PAAC)
print(confusion_matrix(testY_PAAC,y_pred_class_PAAC))
print(metrics_PAAC)
print(accuracy_PAAC)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_PAAC, y_pred_class_PAAC)
auc_keras_PAAC= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_PAAC1,accuracy_PAAC,auc_keras_PAAC,'PAAC',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_PAAC))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""Zscale"""

Z_df=pd.read_csv('ZScale.csv')
Z_df = Z_df.drop('Unnamed: 0',axis=1)

key_df_Z= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_Z= pd.concat([key_df_Z, Z_df], axis=1)
fea_df_Z= fea_df_Z.set_index('sequence')
fea_df_Z['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_Z= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_Z= pos_sequence_Z.index
for i in range (fea_df_Z.shape[0]):
  if(fea_df_Z.index[i] in data_pos_sequence_index_Z):
    fea_df_Z.at[fea_df_Z.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_Z= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_Z= neg_sequence_Z.index
for i in range (fea_df_Z.shape[0]):
  if(fea_df_Z.index[i] in data_neg_sequence_index_Z):
    fea_df_Z.at[fea_df_Z.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_Z.drop(fea_df_Z[fea_df_Z.Class == -1].index, inplace=True)
fea_df_Z= fea_df_Z.dropna()
fea_df_Z= fea_df_Z.reset_index(drop=True)

#Separation of features and target
X_Z= fea_df_Z.drop('Class', axis=1)
Y_Z= fea_df_Z['Class']
Y_Z= Y_Z.values.flatten()

trainX_Z, testX_Z, trainY_Z, testY_Z= train_test_split(X_Z, Y_Z, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_Z = sc.fit_transform(trainX_Z)
testX_Z= sc.transform(testX_Z)

#K-Fold validation
classifier_Z = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_Z, trainX_Z, trainY_Z, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_Z.fit(trainX_Z, trainY_Z)
y_pred_class_Z= classifier_Z.predict(testX_Z)

cf_matrix_Z = confusion_matrix(testY_Z,y_pred_class_Z)
metrics_Z = classification_report(testY_Z,y_pred_class_Z)
metrics_Z1 = classification_report(testY_Z,y_pred_class_Z, output_dict=True)
accuracy_Z= accuracy_score(testY_Z, y_pred_class_Z)
print("accuracy:", accuracy_Z)
print(confusion_matrix(testY_Z,y_pred_class_Z))
print(metrics_Z)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_Z, y_pred_class_Z)
auc_keras_Z= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_Z1,accuracy_Z,auc_keras_Z,'ZsCale',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_Z))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""TPC"""

TPC1_df=pd.read_csv('TPC1.csv')
TPC1_df = TPC1_df.drop('Unnamed: 0',axis=1)

key_df_TPC1= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_TPC1= pd.concat([key_df_TPC1, TPC1_df], axis=1)
fea_df_TPC1= fea_df_TPC1.set_index('sequence')
fea_df_TPC1['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_TPC1= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_TPC1= pos_sequence_TPC1.index
for i in range (fea_df_TPC1.shape[0]):
  if(fea_df_TPC1.index[i] in data_pos_sequence_index_TPC1):
    fea_df_TPC1.at[fea_df_TPC1.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_TPC1= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_TPC1= neg_sequence_TPC1.index
for i in range (fea_df_TPC1.shape[0]):
  if(fea_df_TPC1.index[i] in data_neg_sequence_index_TPC1):
    fea_df_TPC1.at[fea_df_TPC1.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_TPC1.drop(fea_df_TPC1[fea_df_TPC1.Class == -1].index, inplace=True)
fea_df_TPC1= fea_df_TPC1.dropna()
fea_df_TPC1= fea_df_TPC1.reset_index(drop=True)

#Separation of features and target
X_TPC1= fea_df_TPC1.drop('Class', axis=1)
Y_TPC1= fea_df_TPC1['Class']
Y_TPC1= Y_TPC1.values.flatten()

trainX_TPC1, testX_TPC1, trainY_TPC1, testY_TPC1= train_test_split(X_TPC1, Y_TPC1, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_TPC1= sc.fit_transform(trainX_TPC1)
testX_TPC1= sc.transform(testX_TPC1)

#K-Fold validation
classifier_TPC1 = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_TPC1, trainX_TPC1, trainY_TPC1, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_TPC1.fit(trainX_TPC1, trainY_TPC1)
y_pred_class_TPC1= classifier_TPC1.predict(testX_TPC1)

cf_matrix_TPC1 = confusion_matrix(testY_TPC1,y_pred_class_TPC1)
metrics_TPC1 = classification_report(testY_TPC1,y_pred_class_TPC1)
metrics_TPC11 = classification_report(testY_TPC1,y_pred_class_TPC1, output_dict=True)
accuracy_TPC1= accuracy_score(testY_TPC1, y_pred_class_TPC1)
print("accuracy:", accuracy_TPC1)
print(confusion_matrix(testY_TPC1,y_pred_class_TPC1))
print(metrics_TPC1)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_TPC1, y_pred_class_TPC1)
auc_keras_TPC1= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_TPC11,accuracy_TPC1,auc_keras_TPC1,'TPC1',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_TPC1))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""TPC2"""

TPC2_df=pd.read_csv('TPC2.csv')
TPC2_df = TPC2_df.drop('Unnamed: 0',axis=1)

key_df_TPC2= pd.read_csv('merged.csv', usecols=['sequence'])
fea_df_TPC2= pd.concat([key_df_TPC2, TPC2_df], axis=1)
fea_df_TPC2= fea_df_TPC2.set_index('sequence')
fea_df_TPC2['Class'] = -1

#labeling of sequences positive sequences of the dataset
pos_sequence_TPC2= pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index_TPC2= pos_sequence_TPC2.index
for i in range (fea_df_TPC2.shape[0]):
  if(fea_df_TPC2.index[i] in data_pos_sequence_index_TPC2):
    fea_df_TPC2.at[fea_df_TPC2.index[i],'Class'] = 1

#labeling of sequences negtive sequences of the dataset
neg_sequence_TPC2= pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index_TPC2= neg_sequence_TPC2.index
for i in range (fea_df_TPC2.shape[0]):
  if(fea_df_TPC2.index[i] in data_neg_sequence_index_TPC2):
    fea_df_TPC2.at[fea_df_TPC2.index[i],'Class'] = 0

#deletion of sequences having no label
fea_df_TPC2.drop(fea_df_TPC2[fea_df_TPC2.Class == -1].index, inplace=True)
fea_df_TPC2= fea_df_TPC2.dropna()
fea_df_TPC2= fea_df_TPC2.reset_index(drop=True)

#Separation of features and target
X_TPC2= fea_df_TPC2.drop('Class', axis=1)
Y_TPC2= fea_df_TPC2['Class']
Y_TPC2= Y_TPC2.values.flatten()

trainX_TPC2, testX_TPC2, trainY_TPC2, testY_TPC2= train_test_split(X_TPC2, Y_TPC2, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX_TPC2= sc.fit_transform(trainX_TPC2)
testX_TPC2= sc.transform(testX_TPC2)

#K-Fold validation
classifier_TPC2 = RandomForestClassifier(n_estimators=20, random_state=20)
RF_scores = cross_val_score(classifier_TPC2, trainX_TPC2, trainY_TPC2, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (RF_scores.mean(), RF_scores.std()))
print(RF_scores)

classifier_TPC2.fit(trainX_TPC2, trainY_TPC2)
y_pred_class_TPC2= classifier_TPC2.predict(testX_TPC2)

cf_matrix_TPC2 = confusion_matrix(testY_TPC2,y_pred_class_TPC2)
metrics_TPC2 = classification_report(testY_TPC2,y_pred_class_TPC2)
metrics_TPC21 = classification_report(testY_TPC2,y_pred_class_TPC2, output_dict=True)
accuracy_TPC2= accuracy_score(testY_TPC2, y_pred_class_TPC2)
print("accuracy:", accuracy_TPC2)
print(confusion_matrix(testY_TPC2,y_pred_class_TPC2))
print(metrics_TPC2)

nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(testY_TPC2, y_pred_class_TPC2)
auc_keras_TPC2= auc(nn_fpr_keras, nn_tpr_keras)
get_metrics('sub_group_model_metrics.csv',metrics_TPC21,accuracy_TPC2,auc_keras_TPC2,'TPC2',False)

plt.figure(1)
plt.plot([0, 1], [0, 1])
plt.plot(nn_fpr_keras, nn_tpr_keras, label='ROC Curve (area = {:.3f})'.format(auc_keras_TPC2))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.fill_between(nn_fpr_keras, nn_tpr_keras, 0, facecolor='lightblue', alpha=0.5)
plt.show()

"""Featuring Cont"""

features_df=pd.concat([AAC_df,CKSAAP_df,CTDC_df,CTDD_df,CTDT_df,DPC1_df, KNN_df,
                       SOC_df, AA_df, AC_df, PAAC_df, Moran_df, Geary_df, Z_df, DPC2_df,
                       TPC1_df, TPC2_df, NMBroto_df, CC_df, GAAC_df, QSOrder_df],axis=1)
features_df = features_df.dropna(how='all',axis=1)
features_df = features_df.drop_duplicates()
features_df.head()
features_df.to_csv('features.csv')

data_df=pd.read_csv('features.csv')
data_df= data_df.drop("Unnamed: 0", axis='columns')

column_headers = list(data_df.columns.values)
print("The Column Header :", column_headers)
print( len(column_headers))

key_df = pd.read_csv('merged.csv', usecols=['sequence'])
fea_df = pd.concat([key_df, data_df], axis=1)
fea_df = fea_df.set_index('sequence')
fea_df.head()

fea_df['Class'] = -1
fea_df.head()

#labeling of sequences positive sequences of the dataset
pos_sequence = pd.read_csv('pos.csv', index_col=['sequence'])
data_pos_sequence_index = pos_sequence.index
for i in range (fea_df.shape[0]):
  if(fea_df.index[i] in data_pos_sequence_index):
    fea_df.at[fea_df.index[i],'Class'] = 1
fea_df.head()

#labeling of sequences negtive sequences of the dataset
neg_sequence = pd.read_csv('Neg.csv', index_col=['sequence'])
data_neg_sequence_index = neg_sequence.index
for i in range (fea_df.shape[0]):
  if(fea_df.index[i] in data_neg_sequence_index):
    fea_df.at[fea_df.index[i],'Class'] = 0
fea_df.tail(500)

fea_df.drop(fea_df[fea_df.Class == -1].index, inplace=True)
fea_df = fea_df.dropna()
fea_df = fea_df.reset_index(drop=True)
fea_df.tail(10)

print('total number of features', fea_df.shape[1])

fea_df.to_csv('featureslabelrecA.csv')
files.download('featureslabelrecA.csv')

fea_df=pd.read_csv('featureslabelrecA.csv')
fea_df = fea_df.iloc[:, 1:]
fea_df.head()

fea_df.shape

!pip install scikit-learn==1.5.1

"""ML model"""

#Separation of features and target
X = fea_df.drop('Class', axis=1)
Y = fea_df['Class']
Y = Y.values.flatten()
Y

trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.30, random_state=6)

sc = StandardScaler()
trainX = sc.fit_transform(trainX)
testX = sc.transform(testX)

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import cross_validate, train_test_split
from sklearn.datasets import make_classification
from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score

params = {
    'objective': 'binary:logistic',
    'max_depth': 4,
    'alpha': 10,
    'learning_rate': .01,
    'n_estimators': 100
}

# Initialize classifiers
svm_clf = SVC(gamma='auto', probability=True)
rf_clf = RandomForestClassifier(n_estimators=20, random_state=20)
xgb_clf = XGBClassifier(**params)
lr_clf = LogisticRegression()
nn_clf = MLPClassifier()

classifiers = [svm_clf, rf_clf, xgb_clf,  lr_clf, nn_clf]
classifiers_names = ['SVM', 'RandomForest', 'XG', 'LogisticRegression', 'NeuralNetwork']

cv_results = []  # Fix: Use cv_results instead of results

# Fit classifiers and evaluate
for clf, name in zip(classifiers, classifiers_names):
    # Cross-validation scores
    scores = cross_validate(clf, trainX, trainY, cv=5, n_jobs=-1)

    # Calculate mean and std for test scores
    mean_accuracy = scores['test_score'].mean()
    std_accuracy = scores['test_score'].std()

    # Store CV results
    cv_results.append([name, *scores['test_score'].tolist(), mean_accuracy, std_accuracy])

    # Train classifier on full data
    clf.fit(trainX, trainY)

    # Predictions
    pred = clf.predict(testX)
    prob_y = clf.predict_proba(testX)[:, 1]

    # Compute evaluation metrics
    precision = precision_score(testY, pred)
    recall = recall_score(testY, pred)
    f1 = f1_score(testY, pred)
    fpr, tpr, _ = roc_curve(testY, prob_y)
    auc_score = auc(fpr, tpr)

    # Store evaluation metrics for the classifier
    cv_results[-1].extend([precision, recall, f1, auc_score])

# Convert results to DataFrame
columns = ['Classifier', 'CV1', 'CV2', 'CV3', 'CV4', 'CV5', 'Mean CV', 'SD CV', 'Precision', 'Recall', 'F1-score', 'ROC AUC']
cv_results_df = pd.DataFrame(cv_results, columns=columns)

# Print results
print(cv_results_df)

# Plot ROC curve
plt.figure(figsize=(10, 6))
for clf, name in zip(classifiers, classifiers_names):
    prob_y = clf.predict_proba(testX)[:, 1]
    fpr, tpr, _ = roc_curve(testY, prob_y)
    auc_score = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.2f})')

# Plot ROC curve for random guessing
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guessing')

# Add labels and legend
plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')
plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')
plt.title('ROC Curve', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(False)

# Set ticks to bold
plt.xticks(fontweight='bold')
plt.yticks(fontweight='bold')

# Show plot
plt.show()

cv_results_df.to_csv('cv_results.csv', index=False)

